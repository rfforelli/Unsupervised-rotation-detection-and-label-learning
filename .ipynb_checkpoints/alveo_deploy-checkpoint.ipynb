{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36f1648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils    import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from sklearn.datasets        import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing   import LabelEncoder, StandardScaler\n",
    "\n",
    "\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" \n",
    "os.environ['PATH'] = '/home/ferroelectric/Xilinx_2020/Vivado/2020.1/bin:' + os.environ['PATH']\n",
    "os.environ['PATH'] = '/home/ferroelectric/Xilinx_2020/Vitis/2020.1/bin:' + os.environ['PATH']\n",
    "# os.environ['PATH'] = '/tools/Xilinx/Vivado/2019.2/bin:' + os.environ['PATH']\n",
    "\n",
    "import tensorflow        as tf\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4d6d575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ferroelectric/Desktop/Unsupervised-rotation-detection-and-label-learning\r\n"
     ]
    }
   ],
   "source": [
    "curr_dir = '/home/ferroelectric/Desktop/ryan/IP_builds/06_17_22/test2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8844c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create HLS_projects folder in current working directory\n",
    "USER_PATH    = os.getcwd()\n",
    "DATA_PATH    = USER_PATH + \"curr_dir/Data/\"\n",
    "MODEL_PATH   = USER_PATH + \"curr_dir/Models/\"\n",
    "PROJECT_PATH = USER_PATH + \"curr_dir/HLS_projects/\"\n",
    "PLOTS_PATH   = USER_PATH + \"curr_dir/Plots/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f35ed425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models       import Sequential\n",
    "from tensorflow.keras.optimizers   import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.layers       import Activation, BatchNormalization, Flatten, MaxPool2D, Reshape\n",
    "from tensorflow.keras.layers       import Dense, Conv2D\n",
    "\n",
    "#import utils\n",
    "#from utils.callbacks import all_callbacks\n",
    "\n",
    "from qkeras.qlayers    import QDense, QActivation\n",
    "from qkeras            import QConv2D, QConv1D\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu, quantized_tanh, binary_tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4bea4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distilled_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0905e4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-17 13:45:25.034475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-17 13:45:25.039781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-17 13:45:25.040499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "/home/ferroelectric/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94005179 0.34103164 1.12650526 0.         0.         1.19970393]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-17 13:45:38.101837: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-17 13:45:38.104141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-17 13:45:38.104683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-17 13:45:38.105145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-17 13:45:38.436481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-17 13:45:38.436988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-17 13:45:38.437457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-17 13:45:38.437901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11508 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 120, 120, 1)]     0         \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 30, 30, 1)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 900)               0         \n",
      "                                                                 \n",
      " q_dense (QDense)            (None, 64)                57664     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " q_activation (QActivation)  (None, 64)                0         \n",
      "                                                                 \n",
      " q_dense_1 (QDense)          (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " q_activation_1 (QActivation  (None, 32)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " q_dense_2 (QDense)          (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " q_activation_2 (QActivation  (None, 16)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " q_dense_3 (QDense)          (None, 6)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,822\n",
      "Trainable params: 60,598\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-17 13:45:43.931311: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3019852800 exceeds 10% of free system memory.\n",
      "2022-06-17 13:45:45.169143: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3019852800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-17 13:45:47.318389: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  34/1639 [..............................] - ETA: 7s - loss: 0.4740 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-17 13:45:47.777353: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1630/1639 [============================>.] - ETA: 0s - loss: 0.0667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-17 13:45:56.638624: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 755020800 exceeds 10% of free system memory.\n",
      "2022-06-17 13:45:56.966577: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 755020800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1639/1639 [==============================] - 12s 6ms/step - loss: 0.0665 - val_loss: 0.6449\n",
      "Epoch 2/30\n",
      "1337/1639 [=======================>......] - ETA: 1s - loss: 0.0270"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 146>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# In[15]:\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_scal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/alveo_tutorial_env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/alveo_tutorial_env/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/alveo_tutorial_env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/alveo_tutorial_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/alveo_tutorial_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/alveo_tutorial_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/alveo_tutorial_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/alveo_tutorial_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/alveo_tutorial_env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# #!/usr/bin/env python\n",
    "# # coding: utf-8\n",
    "\n",
    "# # In[1]:\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# import h5py\n",
    "# import os\n",
    "# from random import shuffle\n",
    "# import tensorflow as tf\n",
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "# import matplotlib.pyplot as plt\n",
    "# import argparse\n",
    "# from distilled_model import *\n",
    "# #, create_quantized_distilled_model, create_extra_small_quantized_distilled_model\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "# import yaml\n",
    "# import math\n",
    "# import tqdm as notebook_tqdm\n",
    "# import hls4ml\n",
    "\n",
    "\n",
    "# # In[2]:\n",
    "\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "\n",
    "# # In[3]:\n",
    "\n",
    "\n",
    "# img = np.load('/home/ferroelectric/Desktop/Unsupervised-rotation-detection-and-label-learning/02_scan_x256_y256_raw.npy')\n",
    "\n",
    "\n",
    "# # In[4]:\n",
    "\n",
    "\n",
    "# img.shape\n",
    "\n",
    "\n",
    "# # In[5]:\n",
    "\n",
    "\n",
    "# img = np.transpose(img,(2,3,0,1)) \n",
    "# data_r = np.copy(img)\n",
    "# data_r[data_r>1e3]=1e3\n",
    "# min_ = np.min(data_r) \n",
    "# max_ = np.max(data_r) \n",
    "# data_r = 1.0*(data_r-min_)/(max_-min_)\n",
    "# data_r = data_r.reshape(-1,1,124,124)\n",
    "# data_r_cut = data_r[:,:,2:122,2:122] \n",
    "# data_r_cut = data_r_cut.reshape(256,256,120,120) \n",
    "# data_r_cut = np.rot90(data_r_cut)  \n",
    "# X = data_r_cut.reshape(-1, 120,120)\n",
    "\n",
    "\n",
    "# # In[6]:\n",
    "\n",
    "\n",
    "# X.shape\n",
    "\n",
    "\n",
    "# # In[7]:\n",
    "\n",
    "\n",
    "# # generate outputs/targets\n",
    "# dataset_h5 = h5py.File('/home/ferroelectric/Desktop/Unsupervised-rotation-detection-and-label-learning/unbinned_results.h5','r+')\n",
    "# rots = np.array(dataset_h5['rotation'])\n",
    "# scal = np.array(dataset_h5['scale'])\n",
    "# y = np.concatenate((rots, scal), axis=1)\n",
    "\n",
    "\n",
    "# # In[8]:\n",
    "\n",
    "\n",
    "# y.shape\n",
    "# print(y[0])\n",
    "\n",
    "\n",
    "# # In[9]:\n",
    "\n",
    "\n",
    "# #y = np.load('unbinned_results.npy')\n",
    "# sc = StandardScaler()\n",
    "# y_scal = sc.fit_transform(y)\n",
    "\n",
    "\n",
    "# # In[10]:\n",
    "\n",
    "\n",
    "# y_scal.shape\n",
    "\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # In[11]:\n",
    "\n",
    "\n",
    "# # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "# # # np.save('x_test.npy',X_test)\n",
    "# # # np.save('y_test.npy',y_test)\n",
    "\n",
    "\n",
    "# # In[12]:\n",
    "\n",
    "\n",
    "# precision = 12\n",
    "# model = create_mlp_avg_pool(precision)\n",
    "# optimizer = 'adam'\n",
    "# loss = 'mse'\n",
    "\n",
    "# stopping = EarlyStopping(monitor='val_loss',\n",
    "#                              patience = 10)\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10,\n",
    "#                                   mode='min', verbose=1, min_delta=0.001,\n",
    "#                                   cooldown=4, min_lr=1e-5)\n",
    "# callbacks=[\n",
    "#         stopping,\n",
    "#         reduce_lr,\n",
    "#     ]\n",
    "\n",
    "\n",
    "# # In[13]:\n",
    "\n",
    "\n",
    "# model.compile(optimizer=optimizer, loss=loss,)\n",
    "\n",
    "\n",
    "# # In[14]:\n",
    "\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# # In[15]:\n",
    "\n",
    "\n",
    "# history = model.fit(X,y_scal,\n",
    "#                 epochs=30,\n",
    "#                 batch_size = 32,\n",
    "#                 shuffle=True,\n",
    "#                 validation_split = 0.2,)\n",
    "\n",
    "\n",
    "# # In[16]:\n",
    "\n",
    "\n",
    "# # history = MODEL.fit(X,y_scal,\n",
    "# #                 epochs=100,\n",
    "# #                 batch_size = 32,\n",
    "# #                 shuffle=True,\n",
    "# #                 validation_split = 0.2,\n",
    "# #                 callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b29219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from qkeras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a1e772",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.load('/home/ferroelectric/Desktop/Unsupervised-rotation-detection-and-label-learning/02_scan_x256_y256_raw.npy')\n",
    "\n",
    "img = np.transpose(img,(2,3,0,1)) \n",
    "data_r = np.copy(img)\n",
    "data_r[data_r>1e3]=1e3\n",
    "min_ = np.min(data_r) \n",
    "max_ = np.max(data_r) \n",
    "data_r = 1.0*(data_r-min_)/(max_-min_)\n",
    "data_r = data_r.reshape(-1,1,124,124)\n",
    "data_r_cut = data_r[:,:,2:122,2:122] \n",
    "data_r_cut = data_r_cut.reshape(256,256,120,120) \n",
    "data_r_cut = np.rot90(data_r_cut)  \n",
    "X = data_r_cut.reshape(-1, 120,120)\n",
    "\n",
    "X_test = np.ascontiguousarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ac04ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict(d, indent=0):\n",
    "    align = 20\n",
    "    for key, value in d.items():\n",
    "        print('  ' * indent + str(key), end='')\n",
    "        if isinstance(value, dict):\n",
    "            print()\n",
    "            print_dict(value, indent+1)\n",
    "        else:\n",
    "            print(':' + ' ' * (20 - len(key) - 2 * indent) + str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa6ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import hls4ml\n",
    "# import python_utils\n",
    "# #from utils import plotting\n",
    "# hls4ml.model.optimizer.get_optimizer('output_rounding_saturation_mode').configure(layers=['Activation'], rounding_mode='AP_RND', saturation_mode='AP_SAT')\n",
    "\n",
    "    \n",
    "# config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "# REUSE_FACTOR = 64\n",
    "# config['Model']['ReuseFactor'] = REUSE_FACTOR\n",
    "# #config['SkipOptimizers'] = ['reshape_stream']\n",
    "# #config['SkipOptimizers']= ['relu_merge']\n",
    "# config['Model']['Strategy'] = 'Resource'\n",
    "# config['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "# #config['Model']['Compression'] = 'True'\n",
    "\n",
    "# config['OutputDir'] = '/home/ferroelectric/Desktop/ryan/IP_builds/06_17_22/mlp_average_pool_12b_quant_1'\n",
    "\n",
    "# for layer in config['LayerName'].keys():\n",
    "#     config['LayerName'][layer]['Trace'] = True\n",
    "#     config['LayerName'][layer]['ReuseFactor'] = REUSE_FACTOR\n",
    "\n",
    "\n",
    "    \n",
    "# # config['LayerName']['input_1']['Precision']['weight'] = 'ap_fixed<32,16>'\n",
    "# # config['LayerName']['input_1']['Precision']['result'] = 'ap_fixed<32,16>'\n",
    "\n",
    "# # config['LayerName']['q_dense']['Precision']['weight'] = 'ap_fixed<12,4>'\n",
    "# # config['LayerName']['q_dense']['Precision']['bias'] = 'ap_fixed<12,4>'\n",
    "# # config['LayerName']['q_dense_1']['Precision']['weight'] = 'ap_fixed<12,4>'\n",
    "# # config['LayerName']['q_dense_1']['Precision']['bias'] = 'ap_fixed<12,4>'\n",
    "# # config['LayerName']['q_dense_2']['Precision']['weight'] = 'ap_fixed<12,4>'\n",
    "# # config['LayerName']['q_dense_2']['Precision']['bias'] = 'ap_fixed<12,4>'\n",
    "# # config['LayerName']['q_dense_3']['Precision']['weight'] = 'ap_fixed<12,4>'\n",
    "# # config['LayerName']['q_dense_3']['Precision']['bias'] = 'ap_fixed<12,4>'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # config['LayerName']['layer0']['Precision'] = 'ap_ufixed<8,3>'\n",
    "\n",
    "# # config['LayerName']['q_dense']['ReuseFactor'] = 28\n",
    "# # #config['LayerName']['q_dense']['Precision']['weight']   = 'ap_fixed<2,1>'\n",
    "# # #config['LayerName']['q_dense']['Precision']['bias']     = 'ap_fixed<11,3>'\n",
    "# # config['LayerName']['q_dense']['Precision']['result']   = 'ap_fixed<9,4>'\n",
    "# # config['LayerName']['q_dense']['Trace']       = Trace\n",
    "# # #config['LayerName']['q_dense']['Strategy'] = 'Latency'\n",
    "\n",
    "# # config['LayerName']['q_dense_1']['ReuseFactor'] = 20\n",
    "# # #config['LayerName']['q_dense_1']['Precision']['weight']   = 'ap_fixed<3,1>'\n",
    "# # #config['LayerName']['q_dense_1']['Precision']['bias']     = 'ap_fixed<11,3>'\n",
    "# # config['LayerName']['q_dense_1']['Precision']['result']   = 'ap_fixed<8,4>'\n",
    "# # config['LayerName']['q_dense_1']['Trace']       = Trace\n",
    "# # #config['LayerName']['q_dense_1']['Strategy'] = 'Latency'\n",
    "\n",
    "# # config['LayerName']['softmax']['exp_table_t'] = 'ap_fixed<12,4>'\n",
    "# # config['LayerName']['softmax']['inv_table_t'] = 'ap_fixed<12,2>'\n",
    "# # config['LayerName']['softmax']['table_size']  = 1024\n",
    "# # config['LayerName']['softmax']['Precision']   = 'ap_fixed<14,2>'\n",
    "# # config['LayerName']['softmax']['Strategy']    = 'Stable'\n",
    "# # config['LayerName']['softmax']['Trace']       = Trace\n",
    "\n",
    "\n",
    "# cfg = hls4ml.converters.create_config(board='alveo-u200', clock_period= 5, part='xcu200-fsgd2104-2-e', backend='VivadoAccelerator')\n",
    "# cfg['HLSConfig'] = config\n",
    "\n",
    "# cfg['AcceleratorConfig']['Driver']    = 'python'\n",
    "# cfg['AcceleratorConfig']['Board']     = 'alveo-u200'\n",
    "# cfg['AcceleratorConfig']['Interface'] = 'axi_stream'\n",
    "# #cfg['AcceleratorConfig']['Interface'] = 'axi_lite'\n",
    "# #cfg['AcceleratorConfig']['Interface'] = 'axi_master'\n",
    "# cfg['AcceleratorConfig']['Precision']['Input']  = 'float'\n",
    "# cfg['AcceleratorConfig']['Precision']['Output'] = 'float'\n",
    "\n",
    "# cfg['IOType']= 'io_parallel'\n",
    "# cfg['KerasModel'] = model\n",
    "# cfg['OutputDir'] = PROJECT_PATH + 'Qkeras_pruned_Dense/hls4ml_PYNQ_prj'\n",
    "\n",
    "\n",
    "# print(\"-----------------------------------\")\n",
    "# print_dict(cfg)\n",
    "# print(\"-----------------------------------\")\n",
    "# hls_model = hls4ml.converters.keras_to_hls(cfg)\n",
    "# #hls4ml.model.profiling.numerical(model=model, hls_model=hls_model, X=x_test[:1000])\n",
    "# hls4ml.model.optimizer.get_optimizer('output_rounding_saturation_mode').configure(layers=[])\n",
    "# hls4ml.model.profiling.numerical(model=model, hls_model=hls_model, X=X_test[:100])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7eacde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "from random import shuffle\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "from distilled_model import *\n",
    "#, create_quantized_distilled_model, create_extra_small_quantized_distilled_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import yaml\n",
    "import math\n",
    "import tqdm as notebook_tqdm\n",
    "import hls4ml\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "img = np.load('/home/ferroelectric/Desktop/Unsupervised-rotation-detection-and-label-learning/02_scan_x256_y256_raw.npy')\n",
    "\n",
    "\n",
    "img.shape\n",
    "\n",
    "img = np.transpose(img,(2,3,0,1)) \n",
    "data_r = np.copy(img)\n",
    "data_r[data_r>1e3]=1e3\n",
    "min_ = np.min(data_r) \n",
    "max_ = np.max(data_r) \n",
    "data_r = 1.0*(data_r-min_)/(max_-min_)\n",
    "data_r = data_r.reshape(-1,1,124,124)\n",
    "data_r_cut = data_r[:,:,2:122,2:122] \n",
    "data_r_cut = data_r_cut.reshape(256,256,120,120) \n",
    "data_r_cut = np.rot90(data_r_cut)  \n",
    "X = data_r_cut.reshape(-1, 120,120)\n",
    "\n",
    "\n",
    "# generate outputs/targets\n",
    "dataset_h5 = h5py.File('/home/ferroelectric/Desktop/Unsupervised-rotation-detection-and-label-learning/unbinned_results_1.h5','r+')\n",
    "rots = np.array(dataset_h5['rotation'])\n",
    "scal = np.array(dataset_h5['scale'])\n",
    "y = np.concatenate((rots, scal), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#y = np.load('unbinned_results.npy')\n",
    "sc = StandardScaler()\n",
    "y_scal = sc.fit_transform(y)\n",
    "\n",
    "\n",
    "\n",
    "precision = 12\n",
    "model = create_mlp_avg_pool(precision)\n",
    "optimizer = 'adam'\n",
    "loss = 'mse'\n",
    "\n",
    "stopping = EarlyStopping(monitor='val_loss',\n",
    "                             patience = 10)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10,\n",
    "                                  mode='min', verbose=1, min_delta=0.001,\n",
    "                                  cooldown=4, min_lr=1e-5)\n",
    "callbacks=[\n",
    "        stopping,\n",
    "        reduce_lr,\n",
    "    ]\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss,)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.load_weights(\"/home/ferroelectric/Desktop/Unsupervised-rotation-detection-and-label-learning/models/mlp_average_pool_12b/keras_model_results/model_weights.h5\")\n",
    "\n",
    "\n",
    "\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "import argparse\n",
    "import yaml\n",
    "from post_process import post_process\n",
    "\n",
    "\n",
    "def print_dict(d, indent=0):\n",
    "    align = 20\n",
    "    for key, value in d.items():\n",
    "        print('  ' * indent + str(key), end='')\n",
    "        if isinstance(value, dict):\n",
    "            print()\n",
    "            print_dict(value, indent+1)\n",
    "        else:\n",
    "            print(':' + ' ' * (20 - len(key) - 2 * indent) + str(value))\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "import hls4ml\n",
    "#from utils import plotting\n",
    "hls4ml.model.optimizer.get_optimizer('output_rounding_saturation_mode').configure(layers=['Activation'], rounding_mode='AP_RND', saturation_mode='AP_SAT')\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "REUSE_FACTOR = 64\n",
    "config['Model']['ReuseFactor'] = REUSE_FACTOR\n",
    "#config['SkipOptimizers'] = ['reshape_stream']\n",
    "#config['SkipOptimizers']= ['relu_merge']\n",
    "config['Model']['Strategy'] = 'Resource'\n",
    "config['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "#config['Model']['Compression'] = 'True'\n",
    "\n",
    "USER_PATH    = os.getcwd()\n",
    "PROJECT_PATH = USER_PATH + \"/HLS_projects/\"\n",
    "\n",
    "config['OutputDir'] = '/home/ferroelectric/Desktop/ryan/IP_builds/06_17_22/test2'\n",
    "config['IOType'] = 'io_stream'\n",
    "\n",
    "for layer in config['LayerName'].keys():\n",
    "    config['LayerName'][layer]['Trace'] = True\n",
    "    config['LayerName'][layer]['ReuseFactor'] = REUSE_FACTOR\n",
    "\n",
    "\n",
    "    \n",
    "# config['LayerName']['input_1']['Precision']['weight'] = 'ap_fixed<16,6>'\n",
    "# config['LayerName']['input_1']['Precision']['result'] = 'ap_fixed<16,6>'\n",
    "\n",
    "config['LayerName']['q_dense']['Precision']['weight'] = 'ap_fixed<12,4>'\n",
    "config['LayerName']['q_dense']['Precision']['bias'] = 'ap_fixed<12,4>'\n",
    "config['LayerName']['q_dense_1']['Precision']['weight'] = 'ap_fixed<12,4>'\n",
    "config['LayerName']['q_dense_1']['Precision']['bias'] = 'ap_fixed<12,4>'\n",
    "config['LayerName']['q_dense_2']['Precision']['weight'] = 'ap_fixed<12,4>'\n",
    "config['LayerName']['q_dense_2']['Precision']['bias'] = 'ap_fixed<12,4>'\n",
    "config['LayerName']['q_dense_3']['Precision']['weight'] = 'ap_fixed<12,4>'\n",
    "config['LayerName']['q_dense_3']['Precision']['bias'] = 'ap_fixed<12,4>'\n",
    "\n",
    "\n",
    "# config['LayerName']['q_activation']['Precision']['weight'] = 'ap_ufixed<12,0>'\n",
    "#config['LayerName']['q_activation']['Precision']['result'] = 'ap_ufixed<8,4>'\n",
    "# config['LayerName']['q_activation_1']['Precision']['weight'] = 'ap_ufixed<12,0>'\n",
    "#config['LayerName']['q_activation_1']['Precision']['result'] = 'ap_ufixed<8,4>'\n",
    "# config['LayerName']['q_activation_2']['Precision']['weight'] = 'ap_ufixed<12,0>'\n",
    "#config['LayerName']['q_activation_2']['Precision']['result'] = 'ap_ufixed<8,4>'\n",
    "\n",
    "# config['LayerName']['batch_normalization']['Precision']['weight'] = 'ap_fixed<32,16>'\n",
    "# config['LayerName']['batch_normalization']['Precision']['bias'] = 'ap_fixed<32,16>'\n",
    "# config['LayerName']['batch_normalization']['Precision']['scale'] = 'ap_fixed<32,16>'\n",
    "# config['LayerName']['batch_normalization_1']['Precision']['weight'] = 'ap_fixed<32,16>'\n",
    "# config['LayerName']['batch_normalization_1']['Precision']['bias'] = 'ap_fixed<32,16>'\n",
    "# config['LayerName']['batch_normalization_1']['Precision']['scale'] = 'ap_fixed<32,16>'\n",
    "# config['LayerName']['batch_normalization_2']['Precision']['weight'] = 'ap_fixed<32,16>'\n",
    "# config['LayerName']['batch_normalization_2']['Precision']['bias'] = 'ap_fixed<32,16>'\n",
    "# config['LayerName']['batch_normalization_2']['Precision']['scale'] = 'ap_fixed<32,16>'\n",
    "#config['LayerName']['average_pooling2d']['Precision'] = 'ap_fixed<16,2>'\n",
    "\n",
    "# config['LayerName']['average_pooling2d']['ReuseFactor'] = 1\n",
    "# config['LayerName']['q_dense']['ReuseFactor'] = 60 #added\n",
    "# config['LayerName']['q_dense_1']['ReuseFactor'] = 64 #added\n",
    "# config['LayerName']['q_dense_2']['ReuseFactor'] = 64 #added\n",
    "# config['LayerName']['q_dense_3']['ReuseFactor'] = 64 #added\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "cfg = hls4ml.converters.create_config(board='alveo-u200', clock_period= 5, part='xcu200-fsgd2104-2-e', backend='VivadoAccelerator')\n",
    "cfg['HLSConfig'] = config\n",
    "\n",
    "cfg['AcceleratorConfig']['Driver']    = 'python'\n",
    "cfg['AcceleratorConfig']['Board']     = 'alveo-u200'\n",
    "cfg['AcceleratorConfig']['Interface'] = 'axi_stream'\n",
    "#cfg['AcceleratorConfig']['Interface'] = 'axi_lite'\n",
    "#cfg['AcceleratorConfig']['Interface'] = 'axi_master'\n",
    "cfg['AcceleratorConfig']['Precision']['Input']  = 'float'\n",
    "cfg['AcceleratorConfig']['Precision']['Output'] = 'float'\n",
    "\n",
    "cfg['IOType']= 'io_stream'\n",
    "cfg['KerasModel'] = model\n",
    "cfg['OutputDir'] = PROJECT_PATH + 'Qkeras_pruned_Dense/hls4ml_PYNQ_prj'\n",
    "\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "print_dict(cfg)\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = hls4ml.converters.keras_to_hls(cfg)\n",
    "#hls4ml.model.profiling.numerical(model=model, hls_model=hls_model, X=x_test[:1000])\n",
    "hls4ml.model.optimizer.get_optimizer('output_rounding_saturation_mode').configure(layers=[])\n",
    "#hls4ml.model.profiling.numerical(model=model, hls_model=hls_model, X=X_test[:100])\n",
    "\n",
    "print_dict(config)\n",
    "# HLS_MODEL = hls4ml.converters.convert_from_keras_model(MODEL,\n",
    "#                                                     hls_config=config,\n",
    "#                                                     output_dir='/home/ferroelectric/Desktop/Unsupervised-rotation-detection-and-label-learning/models/mlp_average_pool_12b/my-hls-test',\n",
    "#                                                     part='xcu200-fsgd2104-2-e',\n",
    "#                                                     io_type='io_stream')\n",
    "hls_model.compile()\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "from hls4ml.model.profiling import numerical\n",
    "from hls4ml.converters import keras_to_hls\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "\n",
    "\n",
    "# X_test = np.ascontiguousarray(X)\n",
    "#NEEDED to use 2020.1 over 2019.2\n",
    "os.environ['PATH'] = '/home/ferroelectric/Xilinx_2020/Vivado/2020.1/bin:' + os.environ['PATH']\n",
    "os.environ['PATH'] = '/home/ferroelectric/Xilinx_2020/Vitis/2020.1/bin:' + os.environ['PATH']\n",
    "\n",
    "\n",
    "hls_model.build(csim=False,synth=True, vsynth=True, export=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3690b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hls_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on ip_build\n",
    "# hls4ml.report.read_vivado_report('/home/ferroelectric/Desktop/ryan/IP_builds/06_12_22/mlp_average_pool_12b_quant_1/my-hls-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51980c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hls_model.build(csim=False,synth=True,export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db901c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hls_model.build(csim=False,synth=True, vsynth=True, export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c8c715",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source /opt/xilinx/xrt/setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bc0d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.backends.VivadoAcceleratorBackend.make_xclbin(hls_model, 'xilinx_u200_xdma_201830_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8883e103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e29f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alveo_tutorial_env",
   "language": "python",
   "name": "alveo_tutorial_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
